{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gmf import GMF\n",
    "from mlp import MLP\n",
    "from neumf import NeuMF\n",
    "import torch.optim as optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml1m_dir = 'data/yelp/ratings.txt'\n",
    "ml1m_rating = pd.read_csv(ml1m_dir, sep='\\t', header=None, names=['uid', 'rid', 'rating'],  engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = ml1m_rating[['uid']].drop_duplicates()\n",
    "item_id = ml1m_rating[['rid']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122823, 0, (122677,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id['uid'].max(), user_id['uid'].min(), user_id['uid'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28006, 0, (28002,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_id['rid'].max(), item_id['rid'].min(), item_id['rid'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = user_id['uid'].max() - user_id['uid'].min() + 1\n",
    "num_items = item_id['rid'].max() - item_id['rid'].min() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subset = ml1m_rating[['uid', 'rid', 'rating']]\n",
    "user_item_pairs = np.array([list(x)[0:2] for x in subset.values])\n",
    "ratings = np.array([list(x)[2:3] for x in subset.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, user_item_pairs, ratings):\n",
    "        'Initialization'\n",
    "        self.labels  = ratings\n",
    "        self.samples = user_item_pairs\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.samples)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "       # # Load data and get label\n",
    "        #print(\"called get item\")\n",
    "        X = self.samples[index].astype('long')\n",
    "        y = self.labels[index]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmf_config = {'alias': 'train_gmf',\n",
    "              'num_epoch': 8,\n",
    "              'batch_size': 1024,\n",
    "              'adam_lr': 1e-3,\n",
    "              'num_users': num_users,\n",
    "              'num_items': num_items,\n",
    "              'latent_dim': 8,\n",
    "              'l2_regularization': 0.01,\n",
    "              'use_cuda': True,\n",
    "              'device_id': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_config = {'alias': 'mlp_factor8neg4_bz256_166432168_pretrain_reg_0.0000001',\n",
    "              'num_epoch': 5,\n",
    "              'batch_size': 1024, \n",
    "              'num_users': num_users,\n",
    "              'num_items': num_items,\n",
    "              'latent_dim': 8,\n",
    "              'layers': [16,32,16,8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_config = {'alias': 'pretrain_neumf_factor8neg4',\n",
    "                'num_epoch': 6,\n",
    "                'batch_size': 1024,\n",
    "                'num_users': num_users,\n",
    "                'num_items': num_items,\n",
    "                'latent_dim_mf': 8,\n",
    "                'latent_dim_mlp': 8,\n",
    "                'layers': [16,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "                'pretrain': False,\n",
    "                'pretrain_mf': None,\n",
    "                'pretrain_mlp': None\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings = list(np.load(\"train_ratings.npy\"))\n",
    "val_ratings = list(np.load(\"val_ratings.npy\"))\n",
    "test_ratings = list(np.load(\"test_ratings.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_item_pairs = np.array([(x[0:2]) for x in train_ratings])\n",
    "val_user_item_pairs = np.array([(x[0:2]) for x in val_ratings])\n",
    "test_user_item_pairs = np.array([(x[0:2]) for x in val_ratings])\n",
    "train_labels = np.array([(x[2:3]) for x in train_ratings])\n",
    "val_labels = np.array([(x[2:3]) for x in val_ratings])\n",
    "test_labels = np.array([(x[2:3]) for x in val_ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "training_set = Dataset(train_user_item_pairs, train_labels)\n",
    "train_generator = data.DataLoader(training_set, **training_params)\n",
    "val_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "val_set = Dataset(val_user_item_pairs, val_labels)\n",
    "val_generator = data.DataLoader(val_set, **val_params)\n",
    "test_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "test_set = Dataset(test_user_item_pairs, test_labels)\n",
    "test_generator = data.DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_run(model, generator, opt, criterion,mode=\"train\"):\n",
    "    running_loss = 0\n",
    "    if(mode == \"train\"):\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    for local_batch, local_labels in generator:\n",
    "        local_batch  = torch.tensor(local_batch).type(torch.long).to(device)\n",
    "        local_labels = local_labels.type(torch.float).to(device)\n",
    "        y_preds = model(local_batch[:,0], local_batch[:,1])\n",
    "        loss = criterion(y_preds, local_labels)\n",
    "        running_loss += (loss.item()*local_labels.size()[0])\n",
    "        if(mode == \"train\"):\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    avg_loss = running_loss * 1.0 / (len(generator.dataset))\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, generator):\n",
    "    model.eval()\n",
    "    y_preds_all = torch.Tensor().to(device) \n",
    "    y_labels_all = torch.Tensor().to(device) \n",
    "    for local_batch, local_labels in generator:\n",
    "        local_batch  = torch.tensor(local_batch).type(torch.long).to(device)\n",
    "        local_labels = local_labels.type(torch.float).to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(local_batch[:,0], local_batch[:,1])\n",
    "        y_preds_all = torch.cat((y_preds_all,y_preds))\n",
    "        y_labels_all = torch.cat((y_labels_all,local_labels))\n",
    "    return y_preds_all, y_labels_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def evaluate(model, generator):\n",
    "    y_preds_all, y_labels_all = predict(model, generator)  \n",
    "    y_preds = list(y_preds_all.view(1, y_preds_all.size()[0]).to(\"cpu\").numpy()[0])\n",
    "    y_actuals = list(y_labels_all.view(1, y_labels_all.size()[0]).to(\"cpu\").numpy()[0])\n",
    "    #print(type(y_preds), type(y_actuals))\n",
    "    tmse = sum([(a-b) * (a-b) for a,b in zip(y_preds, y_actuals)])\n",
    "    rmse = math.sqrt((1.0*tmse)/len(y_preds))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gmf():\n",
    "    model = GMF(gmf_config).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999),weight_decay=1e-4)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for epoch in range(gmf_config['num_epoch']):\n",
    "        print(\"running epoch \", epoch)\n",
    "        train_mse = epoch_run(model, train_generator, opt, criterion, \"train\")\n",
    "        val_mse = epoch_run(model, val_generator, opt, criterion,\"val\")\n",
    "        print(\"train mse loss => \", train_mse, \"val mse loss => \", val_mse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp():\n",
    "    model = MLP(mlp_config).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999),weight_decay=1e-4)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for epoch in range(mlp_config['num_epoch']):\n",
    "        print(\"running epoch \", epoch)\n",
    "        train_mse = epoch_run(model, train_generator, opt, criterion,\"train\")\n",
    "        val_mse = epoch_run(model, val_generator, opt,criterion, \"val\")\n",
    "        print(\"train mse loss => \", train_mse, \"val mse loss => \", val_mse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neumf():\n",
    "    model = NeuMF(neumf_config).to(device)\n",
    "#     if config['pretrain']:  #TODO:: Manoj\n",
    "#         model.load_pretrain_weights()\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999),weight_decay=1e-4)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for epoch in range(neumf_config['num_epoch']):\n",
    "        print(\"running epoch \", epoch)\n",
    "        train_mse = epoch_run(model, train_generator, opt,criterion, \"train\")\n",
    "        val_mse = epoch_run(model, val_generator, opt,criterion, \"val\")\n",
    "        print(\"train mse loss => \", train_mse, \"val mse loss => \", val_mse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss =>  9.595478486335345 val mse loss =>  6.078701062905395\n",
      "running epoch  1\n",
      "train mse loss =>  4.1054407974208225 val mse loss =>  2.6434405063625026\n",
      "running epoch  2\n",
      "train mse loss =>  2.0464591744939744 val mse loss =>  1.6799269031932915\n",
      "running epoch  3\n",
      "train mse loss =>  1.6296891914957456 val mse loss =>  1.5921714111437466\n",
      "running epoch  4\n",
      "train mse loss =>  1.607191766190543 val mse loss =>  1.5916036133728044\n",
      "running epoch  5\n",
      "train mse loss =>  1.607115447435845 val mse loss =>  1.5916110017050518\n",
      "running epoch  6\n",
      "train mse loss =>  1.607120271086772 val mse loss =>  1.5916304270049932\n",
      "running epoch  7\n",
      "train mse loss =>  1.6071295327888098 val mse loss =>  1.5916016936755122\n"
     ]
    }
   ],
   "source": [
    "gmf_model = train_gmf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss =>  2.088761404724617 val mse loss =>  1.5956651328082017\n",
      "running epoch  1\n",
      "train mse loss =>  1.5162342781998275 val mse loss =>  1.4650156432668133\n",
      "running epoch  2\n",
      "train mse loss =>  1.2962417460996116 val mse loss =>  1.3326339979284552\n",
      "running epoch  3\n",
      "train mse loss =>  1.1947617218902533 val mse loss =>  1.3236104126429726\n",
      "running epoch  4\n",
      "train mse loss =>  1.1414955583747792 val mse loss =>  1.3322711227758965\n"
     ]
    }
   ],
   "source": [
    "mlp_model = train_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss =>  2.2441500270257877 val mse loss =>  1.5899769734830684\n",
      "running epoch  1\n",
      "train mse loss =>  1.5017119352592165 val mse loss =>  1.4346645324747147\n",
      "running epoch  2\n",
      "train mse loss =>  1.2849891046653534 val mse loss =>  1.326437991741831\n",
      "running epoch  3\n",
      "train mse loss =>  1.193985375598415 val mse loss =>  1.3179139418759134\n",
      "running epoch  4\n",
      "train mse loss =>  1.1432111996668568 val mse loss =>  1.322859048140291\n",
      "running epoch  5\n",
      "train mse loss =>  1.0794715754896362 val mse loss =>  1.3427946512008124\n"
     ]
    }
   ],
   "source": [
    "neumf_model = train_neumf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gmf_model.state_dict(), \"./saved_models/gmf.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mlp_model.state_dict(), \"./saved_models/mlp.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(neumf_model.state_dict(), \"./saved_models/neumf.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuMF(\n",
       "  (embedding_user_mlp): Embedding(122824, 8)\n",
       "  (embedding_item_mlp): Embedding(28007, 8)\n",
       "  (embedding_user_mf): Embedding(122824, 8)\n",
       "  (embedding_item_mf): Embedding(28007, 8)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (2): Linear(in_features=16, out_features=8, bias=True)\n",
       "  )\n",
       "  (affine_output): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuMF(neumf_config).to(device)\n",
    "model.load_state_dict(torch.load(\"./saved_models/neumf.dict\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1632848231420039"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

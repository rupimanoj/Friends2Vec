{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gmf import GMF\n",
    "from mlp import MLP\n",
    "from neumf import NeuMF\n",
    "from neumf_social import NeuMF_Social\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/yelp2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings = list(np.load(data_path + \"train_ratings.npy\"))\n",
    "val_ratings = list(np.load(data_path + \"val_ratings.npy\"))\n",
    "test_ratings = list(np.load(data_path + \"test_ratings.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_embeddings_dict = np.load(data_path + \"node2vec_embeddings.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_rating_path = data_path + 'yelp.train.rating'\n",
    "yelp_ratings = pd.read_csv(yelp_rating_path, sep='\\t', header=None, names=['uid', 'rid', 'rating'],  engine='python')\n",
    "user_id = yelp_ratings[['uid']].drop_duplicates()\n",
    "item_id = yelp_ratings[['rid']].drop_duplicates()\n",
    "num_users = user_id['uid'].max() - user_id['uid'].min() + 1\n",
    "num_items = item_id['rid'].max() - item_id['rid'].min() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_social_config = {'alias': 'pretrain_neumf_factor8neg4',\n",
    "                'num_epoch': 25,\n",
    "                'batch_size': 1024,\n",
    "                'num_users': num_users,\n",
    "                'num_items': num_items,\n",
    "                'latent_dim_mf': 16,\n",
    "                'latent_dim_mlp': 16,\n",
    "                'user_social_dim_in':64,\n",
    "                'user_social_dim_out':16,\n",
    "                'layers': [32+64,64,32,16],  # 32 layers[0] is the concat of latent user vector & latent item vector\n",
    "                'pretrain': False,\n",
    "                'pretrain_mf': None,\n",
    "                'pretrain_mlp': None\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "training_set = Dataset(train_ratings, social_embeddings_dict)\n",
    "train_generator = data.DataLoader(training_set, **training_params)\n",
    "val_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "val_set = Dataset(val_ratings, social_embeddings_dict)\n",
    "val_generator = data.DataLoader(val_set, **val_params)\n",
    "test_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "test_set = Dataset(test_ratings, social_embeddings_dict)\n",
    "test_generator = data.DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#neumf_model = train_neumf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_run(model, generator, opt, criterion,mode=\"train\", social=False):\n",
    "    running_loss = 0\n",
    "    if(mode == \"train\"):\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    for local_batch, local_labels in generator:\n",
    "        local_batch_social  = torch.tensor(local_batch[:, 2:]).type(torch.float).to(device)\n",
    "        local_batch  = torch.tensor(local_batch[:, 0:2]).type(torch.long).to(device)\n",
    "        local_labels = local_labels.type(torch.float).to(device)\n",
    "        #print(local_batch.size(), local_batch_social.size())print()\n",
    "        #print(local_batch_social[0:2])\n",
    "        y_preds = model(local_batch[:,0], local_batch[:,1], local_batch_social)\n",
    "        loss = criterion(y_preds, local_labels)\n",
    "        running_loss += (loss.item()*local_labels.size()[0])\n",
    "        if(mode == \"train\"):\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    avg_loss = running_loss * 1.0 / (len(generator.dataset))\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neumf_social():\n",
    "    model = NeuMF_Social(neumf_social_config).to(device)\n",
    "#     if config['pretrain']:  #TODO:: Manoj\n",
    "#         model.load_pretrain_weights()\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999),weight_decay=1e-3)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for epoch in range(neumf_social_config['num_epoch']):\n",
    "        print(\"running epoch \", epoch)\n",
    "        train_mse = epoch_run(model, train_generator, opt,criterion, \"train\")\n",
    "        val_mse = epoch_run(model, val_generator, opt,criterion, \"val\")\n",
    "        print(\"train mse loss => \", train_mse, \"val mse loss => \", val_mse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss =>  2.014326996734747 val mse loss =>  1.5833030669733776\n",
      "running epoch  1\n",
      "train mse loss =>  1.5698018172479076 val mse loss =>  1.5469720956662303\n",
      "running epoch  2\n",
      "train mse loss =>  1.4421149933308384 val mse loss =>  1.3762537545354465\n",
      "running epoch  3\n",
      "train mse loss =>  1.3276422299105408 val mse loss =>  1.3075803487403266\n",
      "running epoch  4\n",
      "train mse loss =>  1.2480872527180884 val mse loss =>  1.2728572447618427\n",
      "running epoch  5\n",
      "train mse loss =>  1.2081705218166596 val mse loss =>  1.2664187953389319\n",
      "running epoch  6\n",
      "train mse loss =>  1.1968335726035866 val mse loss =>  1.2687272026309004\n",
      "running epoch  7\n",
      "train mse loss =>  1.191456978642954 val mse loss =>  1.2681872102268972\n",
      "running epoch  8\n",
      "train mse loss =>  1.1897058591444158 val mse loss =>  1.2748043162039389\n",
      "running epoch  9\n",
      "train mse loss =>  1.188310131953403 val mse loss =>  1.269790938518109\n",
      "running epoch  10\n",
      "train mse loss =>  1.1870152113972159 val mse loss =>  1.2679009847485532\n",
      "running epoch  11\n",
      "train mse loss =>  1.1873011553641206 val mse loss =>  1.2694617350867143\n",
      "running epoch  12\n",
      "train mse loss =>  1.1863037299310266 val mse loss =>  1.264368084572486\n",
      "running epoch  13\n",
      "train mse loss =>  1.1854350004842045 val mse loss =>  1.2645951964494695\n",
      "running epoch  14\n",
      "train mse loss =>  1.1853126926055937 val mse loss =>  1.272087451279803\n",
      "running epoch  15\n",
      "train mse loss =>  1.1849888243625788 val mse loss =>  1.2723085829182874\n",
      "running epoch  16\n",
      "train mse loss =>  1.184711766916111 val mse loss =>  1.2658006657013086\n",
      "running epoch  17\n",
      "train mse loss =>  1.1844821256649845 val mse loss =>  1.2670019591839863\n",
      "running epoch  18\n",
      "train mse loss =>  1.184496105409885 val mse loss =>  1.267330252783482\n",
      "running epoch  19\n",
      "train mse loss =>  1.1842406909789953 val mse loss =>  1.2665299995180714\n",
      "running epoch  20\n",
      "train mse loss =>  1.183832993809274 val mse loss =>  1.2665760887265634\n",
      "running epoch  21\n",
      "train mse loss =>  1.1834223267115067 val mse loss =>  1.2668945795263538\n",
      "running epoch  22\n",
      "train mse loss =>  1.1835619318612134 val mse loss =>  1.265864262264362\n",
      "running epoch  23\n",
      "train mse loss =>  1.183401408349214 val mse loss =>  1.264082344106009\n",
      "running epoch  24\n",
      "train mse loss =>  1.1833857948713726 val mse loss =>  1.269690277412166\n"
     ]
    }
   ],
   "source": [
    "neumf_social_model = train_neumf_social()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(neumf_social_model.state_dict(), \"./saved_models/neumf_social.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuMF_Social(\n",
       "  (embedding_user_mlp): Embedding(122824, 16)\n",
       "  (embedding_item_mlp): Embedding(28007, 16)\n",
       "  (embedding_user_mf): Embedding(122824, 16)\n",
       "  (embedding_item_mf): Embedding(28007, 16)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=96, out_features=64, bias=True)\n",
       "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  )\n",
       "  (affine_output): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuMF_Social(neumf_social_config).to(device)\n",
    "model.load_state_dict(torch.load(\"./saved_models/neumf_social.dict\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, generator):\n",
    "    model.eval()\n",
    "    y_preds_all = torch.Tensor().to(device) \n",
    "    y_labels_all = torch.Tensor().to(device) \n",
    "    for local_batch, local_labels in generator:\n",
    "        local_batch_social  = torch.tensor(local_batch[:, 2:]).type(torch.float).to(device)\n",
    "        local_batch  = torch.tensor(local_batch[:, 0:2]).type(torch.long).to(device)\n",
    "        local_labels = local_labels.type(torch.float).to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(local_batch[:,0], local_batch[:,1], local_batch_social)\n",
    "        y_preds_all = torch.cat((y_preds_all,y_preds))\n",
    "        y_labels_all = torch.cat((y_labels_all,local_labels))\n",
    "    return y_preds_all, y_labels_all\n",
    "\n",
    "def evaluate(model, generator):\n",
    "    y_preds_all, y_labels_all = predict(model, generator)  \n",
    "    y_preds = list(y_preds_all.view(1, y_preds_all.size()[0]).to(\"cpu\").numpy()[0])\n",
    "    y_actuals = list(y_labels_all.view(1, y_labels_all.size()[0]).to(\"cpu\").numpy()[0])\n",
    "    #print(type(y_preds), type(y_actuals))\n",
    "    tmse = sum([(a-b) * (a-b) for a,b in zip(y_preds, y_actuals)])\n",
    "    rmse = math.sqrt((1.0*tmse)/len(y_preds))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1338929320268079"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gmf import GMF\n",
    "from mlp import MLP\n",
    "from neumf import NeuMF\n",
    "from neumf_social import NeuMF_Social\n",
    "import torch.optim as optim\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/yelp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings = list(np.load(data_path + \"train_ratings.npy\"))\n",
    "val_ratings = list(np.load(data_path + \"val_ratings.npy\"))\n",
    "test_ratings = list(np.load(data_path + \"test_ratings.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_embeddings_dict = np.load(data_path + \"deepwalk_embeddings.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_rating_path = data_path + 'yelp.train.rating'\n",
    "yelp_ratings = pd.read_csv(yelp_rating_path, sep='\\t', header=None, names=['uid', 'rid', 'rating'],  engine='python')\n",
    "user_id = yelp_ratings[['uid']].drop_duplicates()\n",
    "item_id = yelp_ratings[['rid']].drop_duplicates()\n",
    "num_users = user_id['uid'].max() - user_id['uid'].min() + 1\n",
    "num_items = item_id['rid'].max() - item_id['rid'].min() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, ratings, social_embeddings_dict):\n",
    "        'Initialization'\n",
    "        self.ratings  = ratings\n",
    "        self.social_embeddings = social_embeddings_dict\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.ratings)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "       # # Load data and get label\n",
    "        user_item_pair = self.ratings[index][0:2].astype('float')\n",
    "        user_social = self.social_embeddings[user_item_pair[0]].astype('float')\n",
    "        #user_social = np.zeros(64).astype('float')\n",
    "        user_item_pair_social = np.concatenate((user_item_pair, user_social), axis=None)\n",
    "        X = user_item_pair_social\n",
    "        y = self.ratings[index][2:3].astype('float')\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmf_config = {'alias': 'train_gmf',\n",
    "              'num_epoch': 8,\n",
    "              'batch_size': 1024,\n",
    "              'adam_lr': 1e-3,\n",
    "              'num_users': num_users,\n",
    "              'num_items': num_items,\n",
    "              'latent_dim': 8,\n",
    "              'l2_regularization': 0.01,\n",
    "              'use_cuda': True,\n",
    "              'device_id': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_config = {'alias': 'mlp_factor8neg4_bz256_166432168_pretrain_reg_0.0000001',\n",
    "              'num_epoch': 5,\n",
    "              'batch_size': 1024, \n",
    "              'num_users': num_users,\n",
    "              'num_items': num_items,\n",
    "              'latent_dim': 8,\n",
    "              'layers': [16,32,16,8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_config = {'alias': 'pretrain_neumf_factor8neg4',\n",
    "                'num_epoch': 6,\n",
    "                'batch_size': 1024,\n",
    "                'num_users': num_users,\n",
    "                'num_items': num_items,\n",
    "                'latent_dim_mf': 8,\n",
    "                'latent_dim_mlp': 8,\n",
    "                'layers': [16,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "                'pretrain': False,\n",
    "                'pretrain_mf': None,\n",
    "                'pretrain_mlp': None\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_social_config = {'alias': 'pretrain_neumf_factor8neg4',\n",
    "                'num_epoch': 8,\n",
    "                'batch_size': 1024,\n",
    "                'num_users': num_users,\n",
    "                'num_items': num_items,\n",
    "                'latent_dim_mf': 8,\n",
    "                'latent_dim_mlp': 8,\n",
    "                'user_social_dim_in':64,\n",
    "                'user_social_dim_out':16,\n",
    "                'layers': [16+16,32,16,8],  # 32 layers[0] is the concat of latent user vector & latent item vector\n",
    "                'pretrain': False,\n",
    "                'pretrain_mf': None,\n",
    "                'pretrain_mlp': None\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "training_set = Dataset(train_ratings, social_embeddings_dict)\n",
    "train_generator = data.DataLoader(training_set, **training_params)\n",
    "val_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "val_set = Dataset(val_ratings, social_embeddings_dict)\n",
    "val_generator = data.DataLoader(val_set, **val_params)\n",
    "test_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "test_set = Dataset(test_ratings, social_embeddings_dict)\n",
    "test_generator = data.DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_run(model, generator, opt, criterion,mode=\"train\", social=False):\n",
    "    running_loss = 0\n",
    "    if(mode == \"train\"):\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    for local_batch, local_labels in generator:\n",
    "        local_batch_social  = torch.tensor(local_batch[:, 2:]).type(torch.float).to(device)\n",
    "        local_batch  = torch.tensor(local_batch[:, 0:2]).type(torch.long).to(device)\n",
    "        local_labels = local_labels.type(torch.float).to(device)\n",
    "        #print(local_batch.size(), local_batch_social.size())\n",
    "        y_preds = model(local_batch[:,0], local_batch[:,1], local_batch_social)\n",
    "        loss = criterion(y_preds, local_labels)\n",
    "        running_loss += (loss.item()*local_labels.size()[0])\n",
    "        if(mode == \"train\"):\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    avg_loss = running_loss * 1.0 / (len(generator.dataset))\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, generator):\n",
    "    model.eval()\n",
    "    y_preds_all = torch.Tensor().to(device) \n",
    "    y_labels_all = torch.Tensor().to(device) \n",
    "    for local_batch, local_labels in generator:\n",
    "        local_batch_social  = torch.tensor(local_batch[:, 2:]).type(torch.float).to(device)\n",
    "        local_batch  = torch.tensor(local_batch).type(torch.long).to(device)\n",
    "        local_labels = local_labels.type(torch.float).to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(local_batch[:,0], local_batch[:,1], local_batch_social)\n",
    "        y_preds_all = torch.cat((y_preds_all,y_preds))\n",
    "        y_labels_all = torch.cat((y_labels_all,local_labels))\n",
    "    return y_preds_all, y_labels_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def evaluate(model, generator):\n",
    "    y_preds_all, y_labels_all = predict(model, generator)  \n",
    "    y_preds = list(y_preds_all.view(1, y_preds_all.size()[0]).to(\"cpu\").numpy()[0])\n",
    "    y_actuals = list(y_labels_all.view(1, y_labels_all.size()[0]).to(\"cpu\").numpy()[0])\n",
    "    #print(type(y_preds), type(y_actuals))\n",
    "    tmse = sum([(a-b) * (a-b) for a,b in zip(y_preds, y_actuals)])\n",
    "    rmse = math.sqrt((1.0*tmse)/len(y_preds))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gmf():\n",
    "    model = GMF(gmf_config).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999),weight_decay=1e-4)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for epoch in range(gmf_config['num_epoch']):\n",
    "        print(\"running epoch \", epoch)\n",
    "        train_mse = epoch_run(model, train_generator, opt, criterion, \"train\")\n",
    "        val_mse = epoch_run(model, val_generator, opt, criterion,\"val\")\n",
    "        print(\"train mse loss => \", train_mse, \"val mse loss => \", val_mse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp():\n",
    "    model = MLP(mlp_config).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999),weight_decay=1e-4)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for epoch in range(mlp_config['num_epoch']):\n",
    "        print(\"running epoch \", epoch)\n",
    "        train_mse = epoch_run(model, train_generator, opt, criterion,\"train\")\n",
    "        val_mse = epoch_run(model, val_generator, opt,criterion, \"val\")\n",
    "        print(\"train mse loss => \", train_mse, \"val mse loss => \", val_mse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neumf():\n",
    "    model = NeuMF(neumf_config).to(device)\n",
    "#     if config['pretrain']:  #TODO:: Manoj\n",
    "#         model.load_pretrain_weights()\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999),weight_decay=1e-4)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for epoch in range(neumf_config['num_epoch']):\n",
    "        print(\"running epoch \", epoch)\n",
    "        train_mse = epoch_run(model, train_generator, opt,criterion, \"train\")\n",
    "        val_mse = epoch_run(model, val_generator, opt,criterion, \"val\")\n",
    "        print(\"train mse loss => \", train_mse, \"val mse loss => \", val_mse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neumf_social():\n",
    "    model = NeuMF_Social(neumf_social_config).to(device)\n",
    "#     if config['pretrain']:  #TODO:: Manoj\n",
    "#         model.load_pretrain_weights()\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999),weight_decay=1e-4)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for epoch in range(neumf_social_config['num_epoch']):\n",
    "        print(\"running epoch \", epoch)\n",
    "        train_mse = epoch_run(model, train_generator, opt,criterion, \"train\")\n",
    "        val_mse = epoch_run(model, val_generator, opt,criterion, \"val\")\n",
    "        print(\"train mse loss => \", train_mse, \"val mse loss => \", val_mse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss =>  9.595478486335345 val mse loss =>  6.078701062905395\n",
      "running epoch  1\n",
      "train mse loss =>  4.1054407974208225 val mse loss =>  2.6434405063625026\n",
      "running epoch  2\n",
      "train mse loss =>  2.0464591744939744 val mse loss =>  1.6799269031932915\n",
      "running epoch  3\n",
      "train mse loss =>  1.6296891914957456 val mse loss =>  1.5921714111437466\n",
      "running epoch  4\n",
      "train mse loss =>  1.607191766190543 val mse loss =>  1.5916036133728044\n",
      "running epoch  5\n",
      "train mse loss =>  1.607115447435845 val mse loss =>  1.5916110017050518\n",
      "running epoch  6\n",
      "train mse loss =>  1.607120271086772 val mse loss =>  1.5916304270049932\n",
      "running epoch  7\n",
      "train mse loss =>  1.6071295327888098 val mse loss =>  1.5916016936755122\n"
     ]
    }
   ],
   "source": [
    "gmf_model = train_gmf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss =>  2.088761404724617 val mse loss =>  1.5956651328082017\n",
      "running epoch  1\n",
      "train mse loss =>  1.5162342781998275 val mse loss =>  1.4650156432668133\n",
      "running epoch  2\n",
      "train mse loss =>  1.2962417460996116 val mse loss =>  1.3326339979284552\n",
      "running epoch  3\n",
      "train mse loss =>  1.1947617218902533 val mse loss =>  1.3236104126429726\n",
      "running epoch  4\n",
      "train mse loss =>  1.1414955583747792 val mse loss =>  1.3322711227758965\n"
     ]
    }
   ],
   "source": [
    "mlp_model = train_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss =>  2.0925040843983993 val mse loss =>  1.826724066453473\n",
      "running epoch  1\n",
      "train mse loss =>  1.3736055020416948 val mse loss =>  1.5246680023304715\n",
      "running epoch  2\n",
      "train mse loss =>  1.1947567357797604 val mse loss =>  1.4640836185916488\n",
      "running epoch  3\n",
      "train mse loss =>  1.1542554382059538 val mse loss =>  1.452479722134367\n",
      "running epoch  4\n",
      "train mse loss =>  1.1299274069102143 val mse loss =>  1.4514484848971039\n",
      "running epoch  5\n",
      "train mse loss =>  1.101578748978171 val mse loss =>  1.455236423131443\n"
     ]
    }
   ],
   "source": [
    "neumf_model = train_neumf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss =>  1.9654662543268306 val mse loss =>  1.8026614366485878\n",
      "running epoch  1\n",
      "train mse loss =>  1.324923334100735 val mse loss =>  1.5044690174713673\n",
      "running epoch  2\n",
      "train mse loss =>  1.1931316683679443 val mse loss =>  1.4641228097475312\n",
      "running epoch  3\n",
      "train mse loss =>  1.1663814631260732 val mse loss =>  1.4548150612595026\n",
      "running epoch  4\n",
      "train mse loss =>  1.149474050849452 val mse loss =>  1.4514291902213132\n",
      "running epoch  5\n",
      "train mse loss =>  1.1308336555022884 val mse loss =>  1.4514488434918573\n",
      "running epoch  6\n",
      "train mse loss =>  1.1113914707063364 val mse loss =>  1.4602239946964948\n",
      "running epoch  7\n",
      "train mse loss =>  1.092948677745897 val mse loss =>  1.4607861819481034\n"
     ]
    }
   ],
   "source": [
    "neumf_social_model = train_neumf_social()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gmf_model.state_dict(), \"./saved_models/gmf.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mlp_model.state_dict(), \"./saved_models/mlp.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(neumf_model.state_dict(), \"./saved_models/neumf.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(neumf_social_model.state_dict(), \"./saved_models/neumf_social.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuMF_Social(\n",
       "  (embedding_user_mlp): Embedding(122824, 8)\n",
       "  (embedding_item_mlp): Embedding(28007, 8)\n",
       "  (embedding_user_mf): Embedding(122824, 8)\n",
       "  (embedding_item_mf): Embedding(28007, 8)\n",
       "  (social_mlp): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (2): Linear(in_features=16, out_features=8, bias=True)\n",
       "  )\n",
       "  (affine_output): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuMF_Social(neumf_social_config).to(device)\n",
    "model.load_state_dict(torch.load(\"./saved_models/neumf_social.dict\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1533523724046224"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gmf import GMF\n",
    "from mlp import MLP\n",
    "from neumf import NeuMF\n",
    "from neumf_social import NeuMF_Social\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/yelp2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings = list(np.load(data_path + \"train_ratings.npy\"))\n",
    "val_ratings = list(np.load(data_path + \"val_ratings.npy\"))\n",
    "test_ratings = list(np.load(data_path + \"test_ratings.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_embeddings_dict = np.load(data_path + \"deepwalk_embeddings.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_rating_path = data_path + 'yelp.train.rating'\n",
    "yelp_ratings = pd.read_csv(yelp_rating_path, sep='\\t', header=None, names=['uid', 'rid', 'rating'],  engine='python')\n",
    "user_id = yelp_ratings[['uid']].drop_duplicates()\n",
    "item_id = yelp_ratings[['rid']].drop_duplicates()\n",
    "num_users = user_id['uid'].max() - user_id['uid'].min() + 1\n",
    "num_items = item_id['rid'].max() - item_id['rid'].min() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_config = {'alias': 'pretrain_neumf_factor8neg4',\n",
    "                'num_epoch': 8,\n",
    "                'batch_size': 1024,\n",
    "                'num_users': num_users,\n",
    "                'num_items': num_items,\n",
    "                'latent_dim_mf': 16,\n",
    "                'latent_dim_mlp': 16,\n",
    "                'layers': [32,16,16],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "                'pretrain': False,\n",
    "                'pretrain_mf': None,\n",
    "                'pretrain_mlp': None\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "training_set = Dataset(train_ratings, social_embeddings_dict)\n",
    "train_generator = data.DataLoader(training_set, **training_params)\n",
    "val_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "val_set = Dataset(val_ratings, social_embeddings_dict)\n",
    "val_generator = data.DataLoader(val_set, **val_params)\n",
    "test_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "test_set = Dataset(test_ratings, social_embeddings_dict)\n",
    "test_generator = data.DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neumf():\n",
    "    model = NeuMF(neumf_config).to(device)\n",
    "#     if config['pretrain']:  #TODO:: Manoj\n",
    "#         model.load_pretrain_weights()\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999),weight_decay=1e-4)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for epoch in range(neumf_config['num_epoch']):\n",
    "        print(\"running epoch \", epoch)\n",
    "        train_mse = epoch_run(model, train_generator, opt,criterion, \"train\")\n",
    "        val_mse = epoch_run(model, val_generator, opt,criterion, \"val\")\n",
    "        print(\"train mse loss => \", train_mse, \"val mse loss => \", val_mse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_run(model, generator, opt, criterion,mode=\"train\", social=False):\n",
    "    running_loss = 0\n",
    "    if(mode == \"train\"):\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    for local_batch, local_labels in generator:\n",
    "        #local_batch_social  = torch.tensor(local_batch[:, 2:]).type(torch.float).to(device)\n",
    "        local_batch  = torch.tensor(local_batch[:, 0:2]).type(torch.long).to(device)\n",
    "        local_labels = local_labels.type(torch.float).to(device)\n",
    "        #print(local_batch.size(), local_batch_social.size())print()\n",
    "        #print(local_batch_social[0:2])\n",
    "        y_preds = model(local_batch[:,0], local_batch[:,1])\n",
    "        loss = criterion(y_preds, local_labels)\n",
    "        running_loss += (loss.item()*local_labels.size()[0])\n",
    "        if(mode == \"train\"):\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    avg_loss = running_loss * 1.0 / (len(generator.dataset))\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss =>  2.3404421378321025 val mse loss =>  1.5859446785060092\n",
      "running epoch  1\n",
      "train mse loss =>  1.5376353755502632 val mse loss =>  1.4348655856710812\n",
      "running epoch  2\n",
      "train mse loss =>  1.3172312867857259 val mse loss =>  1.2849256537619553\n",
      "running epoch  3\n",
      "train mse loss =>  1.2240910843220634 val mse loss =>  1.2662778686663525\n",
      "running epoch  4\n",
      "train mse loss =>  1.1909740134232962 val mse loss =>  1.2614337685023491\n",
      "running epoch  5\n",
      "train mse loss =>  1.1648433423374376 val mse loss =>  1.2596193561117592\n",
      "running epoch  6\n",
      "train mse loss =>  1.134795196279845 val mse loss =>  1.26134630853324\n",
      "running epoch  7\n",
      "train mse loss =>  1.1065654597008752 val mse loss =>  1.2682985374454443\n"
     ]
    }
   ],
   "source": [
    "neumf_model = train_neumf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(neumf_model.state_dict(), \"./saved_models/neumf.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuMF(\n",
       "  (embedding_user_mlp): Embedding(122824, 16)\n",
       "  (embedding_item_mlp): Embedding(28007, 16)\n",
       "  (embedding_user_mf): Embedding(122824, 16)\n",
       "  (embedding_item_mf): Embedding(28007, 16)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       "  (affine_output): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuMF(neumf_config).to(device)\n",
    "model.load_state_dict(torch.load(\"./saved_models/neumf.dict\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, generator):\n",
    "    model.eval()\n",
    "    y_preds_all = torch.Tensor().to(device) \n",
    "    y_labels_all = torch.Tensor().to(device) \n",
    "    for local_batch, local_labels in generator:\n",
    "        #local_batch_social  = torch.tensor(local_batch[:, 2:]).type(torch.float).to(device)\n",
    "        local_batch  = torch.tensor(local_batch[:, 0:2]).type(torch.long).to(device)\n",
    "        local_labels = local_labels.type(torch.float).to(device)\n",
    "        with torch.no_grad():\n",
    "                y_preds = model(local_batch[:,0], local_batch[:,1])\n",
    "        y_preds_all = torch.cat((y_preds_all,y_preds))\n",
    "        y_labels_all = torch.cat((y_labels_all,local_labels))\n",
    "    return y_preds_all, y_labels_all\n",
    "\n",
    "def evaluate(model, generator):\n",
    "    y_preds_all, y_labels_all = predict(model, generator)  \n",
    "    y_preds = list(y_preds_all.view(1, y_preds_all.size()[0]).to(\"cpu\").numpy()[0])\n",
    "    y_actuals = list(y_labels_all.view(1, y_labels_all.size()[0]).to(\"cpu\").numpy()[0])\n",
    "    #print(type(y_preds), type(y_actuals))\n",
    "    tmse = sum([(a-b) * (a-b) for a,b in zip(y_preds, y_actuals)])\n",
    "    rmse = math.sqrt((1.0*tmse)/len(y_preds))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1341272335799366"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

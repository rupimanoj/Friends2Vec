{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gmf import GMF\n",
    "from mlp import MLP\n",
    "from neumf import NeuMF\n",
    "from neumf_social2 import NeuMF_Social_2\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/yelp2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings = list(np.load(data_path + \"train_ratings.npy\"))\n",
    "val_ratings = list(np.load(data_path + \"val_ratings.npy\"))\n",
    "test_ratings = list(np.load(data_path + \"test_ratings.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_embeddings_dict = np.load(data_path + \"node2vec_embeddings.npy\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_rating_path = data_path + 'yelp.train.rating'\n",
    "yelp_ratings = pd.read_csv(yelp_rating_path, sep='\\t', header=None, names=['uid', 'rid', 'rating'],  engine='python')\n",
    "user_id = yelp_ratings[['uid']].drop_duplicates()\n",
    "item_id = yelp_ratings[['rid']].drop_duplicates()\n",
    "num_users = user_id['uid'].max() - user_id['uid'].min() + 1\n",
    "num_items = item_id['rid'].max() - item_id['rid'].min() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_social_config = {'alias': 'pretrain_neumf_factor8neg4',\n",
    "                'num_epoch': 25,\n",
    "                'batch_size': 1024,\n",
    "                'num_users': num_users,\n",
    "                'num_items': num_items,\n",
    "                'latent_dim_mf': 16,\n",
    "                'latent_dim_mlp': 16,\n",
    "                'layers': [32,16,16],  # 32 layers[0] is the concat of latent user vector & latent item vector\n",
    "                'social_layers': [128,32,16],\n",
    "                'pretrain': False,\n",
    "                'pretrain_mf': None,\n",
    "                'pretrain_mlp': None\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "training_set = Dataset(train_ratings, social_embeddings_dict)\n",
    "train_generator = data.DataLoader(training_set, **training_params)\n",
    "val_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "val_set = Dataset(val_ratings, social_embeddings_dict)\n",
    "val_generator = data.DataLoader(val_set, **val_params)\n",
    "test_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "test_set = Dataset(test_ratings, social_embeddings_dict)\n",
    "test_generator = data.DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neumf_social():\n",
    "    model = NeuMF_Social_2(neumf_social_config).to(device)\n",
    "#     if config['pretrain']:  #TODO:: Manoj\n",
    "#         model.load_pretrain_weights()\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999),weight_decay=1e-3)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for epoch in range(neumf_social_config['num_epoch']):\n",
    "        print(\"running epoch \", epoch)\n",
    "        train_mse = epoch_run(model, train_generator, opt,criterion, \"train\")\n",
    "        val_mse = epoch_run(model, val_generator, opt,criterion, \"val\")\n",
    "        print(\"train mse loss => \", train_mse, \"val mse loss => \", val_mse)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_run(model, generator, opt, criterion,mode=\"train\", social=False):\n",
    "    running_loss = 0\n",
    "    if(mode == \"train\"):\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    for local_batch, local_labels in generator:\n",
    "        local_batch_social  = torch.tensor(local_batch[:, 2:]).type(torch.float).to(device)\n",
    "        local_batch  = torch.tensor(local_batch[:, 0:2]).type(torch.long).to(device)\n",
    "        local_labels = local_labels.type(torch.float).to(device)\n",
    "        #print(local_batch.size(), local_batch_social.size())print()\n",
    "        #print(local_batch_social[0:2])\n",
    "        y_preds = model(local_batch[:,0], local_batch[:,1], local_batch_social)\n",
    "        loss = criterion(y_preds, local_labels)\n",
    "        running_loss += (loss.item()*local_labels.size()[0])\n",
    "        if(mode == \"train\"):\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    avg_loss = running_loss * 1.0 / (len(generator.dataset))\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse loss =>  2.2260007730437144 val mse loss =>  1.6120024621575488\n",
      "running epoch  1\n",
      "train mse loss =>  1.5816949237345557 val mse loss =>  1.5721298078850765\n",
      "running epoch  2\n",
      "train mse loss =>  1.490832807102845 val mse loss =>  1.4475319530670383\n",
      "running epoch  3\n",
      "train mse loss =>  1.4056148395776251 val mse loss =>  1.3741927932647218\n",
      "running epoch  4\n",
      "train mse loss =>  1.3264220271771916 val mse loss =>  1.3273381083071858\n",
      "running epoch  5\n",
      "train mse loss =>  1.2748667018577788 val mse loss =>  1.3086775742650851\n",
      "running epoch  6\n",
      "train mse loss =>  1.2529628300058953 val mse loss =>  1.3028345393275362\n",
      "running epoch  7\n",
      "train mse loss =>  1.2426390310260844 val mse loss =>  1.2987778189820502\n",
      "running epoch  8\n",
      "train mse loss =>  1.2380602597793773 val mse loss =>  1.3001947607838185\n",
      "running epoch  9\n",
      "train mse loss =>  1.2335695235093864 val mse loss =>  1.3003243631608437\n",
      "running epoch  10\n",
      "train mse loss =>  1.2297311137929385 val mse loss =>  1.299778223464078\n",
      "running epoch  11\n",
      "train mse loss =>  1.2225427454688997 val mse loss =>  1.296778549478211\n",
      "running epoch  12\n",
      "train mse loss =>  1.2178289489441594 val mse loss =>  1.288675425205554\n",
      "running epoch  13\n",
      "train mse loss =>  1.2137700414871362 val mse loss =>  1.2900968679310139\n",
      "running epoch  14\n",
      "train mse loss =>  1.2102096192935732 val mse loss =>  1.2917856649976354\n",
      "running epoch  15\n",
      "train mse loss =>  1.2082894408159859 val mse loss =>  1.2874162658214734\n",
      "running epoch  16\n",
      "train mse loss =>  1.206186557665469 val mse loss =>  1.284169535424784\n",
      "running epoch  17\n",
      "train mse loss =>  1.203763664062416 val mse loss =>  1.283637847504787\n",
      "running epoch  18\n",
      "train mse loss =>  1.2029202062114912 val mse loss =>  1.2837054630683942\n",
      "running epoch  19\n",
      "train mse loss =>  1.2010395541471286 val mse loss =>  1.2815047186415702\n",
      "running epoch  20\n",
      "train mse loss =>  1.1981478418445062 val mse loss =>  1.2792006702846308\n",
      "running epoch  21\n",
      "train mse loss =>  1.1960962588736248 val mse loss =>  1.2761202215164436\n",
      "running epoch  22\n",
      "train mse loss =>  1.1953210197536654 val mse loss =>  1.2758174924800552\n",
      "running epoch  23\n",
      "train mse loss =>  1.1943140339148877 val mse loss =>  1.2768862435448387\n",
      "running epoch  24\n",
      "train mse loss =>  1.1923438031500213 val mse loss =>  1.2767231731613118\n"
     ]
    }
   ],
   "source": [
    "neumf_model = train_neumf_social()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(neumf_model.state_dict(), \"./saved_models/neumf_social_2.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuMF_Social_2(\n",
       "  (embedding_user_mlp): Embedding(122824, 16)\n",
       "  (embedding_item_mlp): Embedding(28007, 16)\n",
       "  (embedding_user_mf): Embedding(122824, 16)\n",
       "  (embedding_item_mf): Embedding(28007, 16)\n",
       "  (embedding_item_social): Embedding(28007, 64)\n",
       "  (fc_social_layers): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=16, bias=True)\n",
       "  )\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       "  (affine_output): Linear(in_features=48, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuMF_Social_2(neumf_social_config).to(device)\n",
    "model.load_state_dict(torch.load(\"./saved_models/neumf_social_2.dict\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, generator):\n",
    "    model.eval()\n",
    "    y_preds_all = torch.Tensor().to(device) \n",
    "    y_labels_all = torch.Tensor().to(device) \n",
    "    for local_batch, local_labels in generator:\n",
    "        local_batch_social  = torch.tensor(local_batch[:, 2:]).type(torch.float).to(device)\n",
    "        local_batch  = torch.tensor(local_batch[:, 0:2]).type(torch.long).to(device)\n",
    "        local_labels = local_labels.type(torch.float).to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(local_batch[:,0], local_batch[:,1], local_batch_social)\n",
    "        y_preds_all = torch.cat((y_preds_all,y_preds))\n",
    "        y_labels_all = torch.cat((y_labels_all,local_labels))\n",
    "    return y_preds_all, y_labels_all\n",
    "\n",
    "def evaluate(model, generator):\n",
    "    y_preds_all, y_labels_all = predict(model, generator)  \n",
    "    y_preds = list(y_preds_all.view(1, y_preds_all.size()[0]).to(\"cpu\").numpy()[0])\n",
    "    y_actuals = list(y_labels_all.view(1, y_labels_all.size()[0]).to(\"cpu\").numpy()[0])\n",
    "    #print(type(y_preds), type(y_actuals))\n",
    "    tmse = sum([(a-b) * (a-b) for a,b in zip(y_preds, y_actuals)])\n",
    "    rmse = math.sqrt((1.0*tmse)/len(y_preds))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/forcerequestspring19_gmail_com/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1375855525169463"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
